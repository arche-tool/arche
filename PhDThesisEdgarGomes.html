<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta http-equiv="Content-Style-Type" content="text/css" />
  <meta name="generator" content="pandoc" />
  <title>PhDThesisEdgarGomes</title>
  <style type="text/css">code{white-space: pre;}</style>
  <link rel="stylesheet" href="all.css" type="text/css" />
  <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-AMS_CHTML-full" type="text/javascript"></script>
  <script src="collapseTOC.js"></script>
</head>
<body>
<p><nav id=sidebar></p>
<p>About</p>
<ul>
<li><a href="index.html">Home</a></li>
</ul>
<p>Usage</p>
<ul>
<li><a href="usage.html">Usage</a></li>
<li><a href="install.html">Install</a></li>
</ul>
<p></nav></p>
<div id="content">
<div id="TOC">
<ul>
<li><a href="#literature-review">Literature Review</a><ul>
<li><a href="#background">Background</a></li>
<li><a href="#introduction">Introduction</a></li>
<li><a href="#computational-tools">Computational tools</a><ul>
<li><a href="#introduction-1">Introduction</a></li>
<li><a href="#program-languages">Program languages</a></li>
<li><a href="#development-tools">Development tools</a></li>
<li><a href="#stereographic-visualization">Stereographic visualization</a></li>
</ul></li>
</ul></li>
<li><a href="#virmat">VirMat</a><ul>
<li><a href="#generation-of-grains">Generation of grains</a><ul>
<li><a href="#introduction-2">Introduction</a></li>
<li><a href="#morphological-aspects">Morphological aspects</a></li>
<li><a href="#volume-representation">Volume representation</a></li>
<li><a href="#voronoi-cell">Voronoi cell</a></li>
<li><a href="#sphere-packing">Sphere packing</a></li>
<li><a href="#statistical-analysis">Statistical analysis</a></li>
<li><a href="#topological-analysis">Topological analysis</a></li>
</ul></li>
<li><a href="#grain-boundary-surfaces">Grain boundary surfaces</a><ul>
<li><a href="#introduction-3">Introduction</a></li>
<li><a href="#surface-representation">Surface representation</a></li>
<li><a href="#subdivision-surfaces">Subdivision surfaces</a></li>
<li><a href="#subdivision-surface-as-grain-boundary">Subdivision surface as grain boundary</a></li>
</ul></li>
<li><a href="#ch:Orientation">Orientation distribution</a><ul>
<li><a href="#introduction-4">Introduction</a></li>
<li><a href="#crystallographic-orientation">Crystallographic Orientation</a></li>
<li><a href="#symmetry">Symmetry</a></li>
<li><a href="#orientation-representation">Orientation representation</a></li>
<li><a href="#orientation-distribution">Orientation distribution</a></li>
</ul></li>
<li><a href="#texture-sampling">Texture Sampling</a><ul>
<li><a href="#introduction">Introduction</a></li>
<li><a href="#method">Method</a></li>
<li><a href="#example">Example</a></li>
<li><a href="#sampling-distribution">Sampling distribution</a></li>
<li><a href="#new-method-of-sampling-in-the-orientation-space">New Method of Sampling in the Orientation Space</a></li>
<li><a href="#references">References</a></li>
</ul></li>
</ul></li>
<li><a href="#austenite-reconstruction">Austenite Reconstruction</a><ul>
<li><a href="#fully-automated-orientation-relationship-calculation">Fully automated orientation relationship calculation</a></li>
<li><a href="#prior-austenite-reconstruction">Prior austenite reconstruction</a><ul>
<li><a href="#introduction-5">Introduction</a></li>
<li><a href="#orientation-relationship-calculation">Orientation relationship calculation</a></li>
<li><a href="#parent-phase-reconstruction">Parent phase reconstruction</a></li>
<li><a href="#conclusion">Conclusion</a></li>
<li><a href="#references-1">References</a></li>
</ul></li>
<li><a href="#model-validation-and-application">Model Validation and Application</a></li>
</ul></li>
<li><a href="#appendix">Appendix</a><ul>
<li><a href="#delunay-triangulation">Delunay Triangulation</a></li>
<li><a href="#misorientation-definition">Misorientation definition</a></li>
<li><a href="#colophon">Colophon</a></li>
</ul></li>
</ul>
</div>
<div id="main"><p> </p>
<p><img src="frontmatter/logos/UGent" alt="image" style="height:0.5in" /><img src="frontmatter/logos/DMSE" alt="image" style="height:0.5in" /></p>
<h1 id="literature-review">Literature Review</h1>
<h2 id="background">Background</h2>
<h2 id="introduction">Introduction</h2>
<h2 id="computational-tools">Computational tools</h2>
<h3 id="introduction-1">Introduction</h3>
<h3 id="program-languages">Program languages</h3>
<h3 id="development-tools">Development tools</h3>
<h3 id="stereographic-visualization">Stereographic visualization</h3>
<h1 id="virmat">VirMat</h1>
<h2 id="generation-of-grains">Generation of grains</h2>
<h3 id="introduction-2">Introduction</h3>
<h3 id="morphological-aspects">Morphological aspects</h3>
<h3 id="volume-representation">Volume representation</h3>
<h3 id="voronoi-cell">Voronoi cell</h3>
<h3 id="sphere-packing">Sphere packing</h3>
<h3 id="statistical-analysis">Statistical analysis</h3>
<h3 id="topological-analysis">Topological analysis</h3>
<h2 id="grain-boundary-surfaces">Grain boundary surfaces</h2>
<h3 id="introduction-3">Introduction</h3>
<h3 id="surface-representation">Surface representation</h3>
<p>There many possible ways to represent finite surfaces with arbitrary topology. Some of the most common methods will be describe and their main advantages/disadvantages will be highlighted.</p>
<h5 id="polygon">Polygon</h5>
<p>The most simple and straightforward surface representation is the polygon. A grain boundary can be represented by simple (non self-intersecting) polygon where its vertexes, edges and internal area correspond, respectively, to quadruple junctions, triple lines and the grain boundary. Polygons are limited to represent flat grain boundaries and straight triple lines.</p>
<h5 id="voxel">Voxel</h5>
<h5 id="marching-cubes">Marching cubes</h5>
<h5 id="nurbs">NURBS</h5>
<h3 id="subdivision-surfaces">Subdivision surfaces</h3>
<h3 id="subdivision-surface-as-grain-boundary">Subdivision surface as grain boundary</h3>
<h2 id="ch:Orientation">Orientation distribution</h2>
<p>Douglas Hofstadter - Gödel, Escher, Bach: An Eternal Golden Braid - 1999</p>
<p>ome quick intro here...</p>
<h3 id="introduction-4">Introduction</h3>
<h3 id="crystallographic-orientation">Crystallographic Orientation</h3>
<p>Crystallographic orientations, in polycrystalline materials, are represented by a rotation between the crystal lattice and the chosen ERS that is macroscopically fixed to the material. The ERS is normally defined according to the conformation process used to obtain the polycrystalline material. For example, when processed by rolling mills, the RD (direction along the plate displacement), the ND (direction normal to the plate’s surface) and the TD (direction along the axis of the rolls) are used as a reference system. The ERS may change according to the analysis that has to be done or the processing steps involved. For instance, spiral pipes use rolled plates with an angular rotation from the pipe’s axis, and therefore, a new ERS may be defined with the pipe’s axial direction as X-axis, instead.</p>
<p><span class="math display">\[K_{C}=gK_{ERS}\label{eq:ori_def}\]</span></p>
<p>The crystallographic orientation <span class="math inline">\(g\)</span> is defined as the rotation applied to the ERS (<span class="math inline">\(K_{ERS}\)</span>) that brings into coincide with the crystal lattice reference system (<span class="math inline">\(K_{C}\)</span>), see equation <a href="#eq:ori_def" data-reference-type="ref" data-reference="eq:ori_def">[eq:ori_def]</a>. This can also be interpreted as a passive transformation where the basis forming the ERS is transformed into a new basis corresponding to the crystal reference system. The active rotation, on the contrary, rotates a vector and the resulting transformation is still represented on the original basis. Figure <a href="#fig:diff-act-pas-rot" data-reference-type="ref" data-reference="fig:diff-act-pas-rot">[fig:diff-act-pas-rot]</a> shows the difference between active and passive rotation. The active rotation applies the transformation directly to a vector <span class="math inline">\(v_{A}\)</span> represented in the basis <span class="math inline">\(A\)</span>, resulting in a vector <span class="math inline">\(v&#39;_{A}\)</span> that is still represented in the basis <span class="math inline">\(A\)</span>. Conversely, the passive rotation applies the transformation to the basis <span class="math inline">\(A\)</span> and the result is the rotated basis <span class="math inline">\(B\)</span>. In this case, if the vector <span class="math inline">\(v&#39;\)</span> is applied in the basis <span class="math inline">\(B\)</span> then the relation <span class="math inline">\(v_{A}=v&#39;_{B}\)</span> is valid. Note that the rotations, on both transformations, have the same rotation axis but opposite rotation angles.</p>
<p>Rotations, and therefore orientations, are fixed point transformations i.e. they are a linear transformation where at least one point remains invariant, so if <span class="math inline">\(g:\mathbb{R}^{n}\rightarrow\mathbb{R}^{n}\)</span> is a rotation and <span class="math inline">\(u\in\mathbb{R}^{n}\)</span> then <span class="math inline">\(u\)</span> is called fixed point or axis of rotation if and only if <span class="math inline">\(g\left(u\right)=u\)</span>. Rotations also form a mathematical group called <em>rotation group</em> that is a non-abelian group under composition. Let <span class="math inline">\(G\)</span> be the set of linear transformations <span class="math inline">\(g:\mathbb{R}^{n}\rightarrow\mathbb{R}^{n}\)</span> forming the rotation group and <span class="math inline">\(\left(\bullet\right)\)</span> be the binary operator, then the following properties are valid (a graphic illustration of the properties is shown on Figure <a href="#fig:rot-group" data-reference-type="ref" data-reference="fig:rot-group">[fig:rot-group]</a>):</p>
<ul>
<li><p><em>Closure:</em> If <span class="math inline">\(g_{1}\)</span>and <span class="math inline">\(g_{2}\)</span> are two arbitrary rotation (<span class="math inline">\(g_{1}\in G\)</span> and <span class="math inline">\(g_{2}\in G\)</span>) then there is a functional composition operator <span class="math inline">\(\left(\bullet\right):G\times G\rightarrow G\)</span> which implies that <span class="math inline">\(g_{1}\bullet g_{2}\in G\)</span>. It means that the combination of any rotations is always a valid rotation.</p></li>
<li><p><em>Associativity:</em> For <span class="math inline">\(\left\{ g_{1},g_{2},g_{3}\right\} \in G\)</span> then <span class="math inline">\(g_{1}\bullet\left(g_{2}\bullet g_{3}\right)=\left(g_{1}\bullet g_{2}\right)\bullet g_{3}\)</span></p></li>
<li><p><em>Identity element:</em> There an identity element <span class="math inline">\(id\)</span> that composed with any <span class="math inline">\(g\in G\)</span> changes nothing, so the equation <span class="math inline">\(id\bullet g=g\bullet id=g\)</span> is valid.</p></li>
<li><p><em>Inverse element:</em> For any <span class="math inline">\(g\in G\)</span>, there is an element <span class="math inline">\(g^{-1}\)</span> such that the equation <span class="math inline">\(g\bullet g^{-1}=g^{-1}\bullet g=id\)</span> holds valid.</p></li>
<li><p><em>Non-commutativity:</em> If <span class="math inline">\(g_{1}\)</span> and <span class="math inline">\(g_{2}\)</span> are two arbitrary rotation then the equation <span class="math inline">\(g_{1}\bullet g_{2}=g_{1}\bullet g_{2}\)</span> may <em>not</em> be valid.</p></li>
</ul>
<h3 id="symmetry">Symmetry</h3>
<p><span class="math display">\[\begin{alignedat}{1}\left(O_{m}g_{a}\right)\left(O_{n}g_{b}\right)^{-1}=I\\
O_{m}g_{a}O_{n}=g_{b}\\
\left(O_{m}g_{a}\right)O_{n}=g_{b}
\end{alignedat}\]</span></p>
<h3 id="orientation-representation">Orientation representation</h3>
<p>There many ways to represent physical rotations (<span class="math inline">\(\mathbb{R}^{3}\)</span>). The most important ones are described bellow, as well as their advantages/disadvantages and their conversion to quaternions.</p>
<h4 id="matrix-representation">Matrix representation</h4>
<p>Rotation matrix is a square matrix (<span class="math inline">\(n\times n\)</span>) with real values entries (<span class="math inline">\(a_{ij}\in\mathbb{R}^{n}\)</span>) used to perform rotation in the Euclidean space. Moreover, rotation matrices are orthogonal matrices with determinate equal <span class="math inline">\(1\)</span>. These two features can be used as a validation test, for instance, if <span class="math inline">\(R\)</span> is a real square matrix then <span class="math inline">\(R\)</span> can be a valid rotation matrix only if,</p>
<p><span class="math display">\[RR^{T}=I,\det R=1.\]</span></p>
<p>Rotation matrices form a group when using matrix multiplication as function composition. In this case, the group properties are represented as the following:</p>
<ul>
<li><p><em>Closure:</em> If <span class="math inline">\(R_{1}\)</span>and <span class="math inline">\(R_{2}\)</span> are two arbitrary rotation matrices (<span class="math inline">\(R_{1}\in\mathbb{M}\left(n,n\right)\)</span> and <span class="math inline">\(R_{2}\in\mathbb{M}\left(n,n\right)\)</span>) and matrix multiplication is the functional composition then <span class="math inline">\(R_{1}R_{2}=R_{3}\)</span> and <span class="math inline">\(R_{3}\in\mathbb{M}\left(n,n\right)\)</span>. Where <span class="math inline">\(R_{3}\)</span> is the rotation <span class="math inline">\(R_{2}\)</span> followed by the rotation <span class="math inline">\(R_{1}\)</span>.</p></li>
<li><p><em>Associativity:</em> For <span class="math inline">\(\left\{ R_{1},R_{2},R_{3}\right\} \in\mathbb{M}\left(n,n\right)\)</span> then <span class="math inline">\(R_{1}\left(R_{2}R_{3}\right)=\left(R_{1}R_{2}\right)R_{3}\)</span></p></li>
<li><p><em>Identity element:</em> <span class="math inline">\(id=I\)</span> is the identity matrix (when all the elements are <span class="math inline">\(0\)</span> but the elements of the diagonal which are <span class="math inline">\(1\)</span>). Therefore <span class="math inline">\(IR=RI=R\)</span> is valid.</p></li>
<li><p><em>Inverse element:</em> Due the orthogonality of rotation matrices, the relation <span class="math inline">\(RR^{T}=I=RR^{-1}\)</span> is valid. Therefore the inverse rotation is the transpose matrix, <span class="math inline">\(R^{-1}=R^{T}\)</span>.</p></li>
</ul>
<p>Simple rotation around the Cartesian (<span class="math inline">\(\mathbb{R}^{3}\)</span>) axes are given as an example in the equation <a href="#eq:simpleRotMat" data-reference-type="ref" data-reference="eq:simpleRotMat">[eq:simpleRotMat]</a>, where <span class="math inline">\(\phi\)</span> is the angle of rotation.</p>
<p><span class="math display">\[\begin{alignedat}{1}R_{x}\left(\phi\right)=\left[\begin{array}{ccc}
1 &amp; 0 &amp; 0\\
0 &amp; \cos\phi &amp; \sin\phi\\
0 &amp; -\sin\phi &amp; \cos\phi
\end{array}\right]\\
R_{y}\left(\phi\right)=\left[\begin{array}{ccc}
\cos\phi &amp; 0 &amp; -\sin\phi\\
0 &amp; 1 &amp; 0\\
\sin\phi &amp; 0 &amp; \cos\phi
\end{array}\right]\\
R_{z}\left(\phi\right)=\left[\begin{array}{ccc}
\cos\phi &amp; \sin\phi &amp; 0\\
-\sin\phi &amp; \cos\phi &amp; 0\\
0 &amp; 0 &amp; 1
\end{array}\right]
\end{alignedat}
\label{eq:simpleRotMat}\]</span></p>
<p>When rotation matrices are used to represent orientations, its rows and columns have special meaning. The rows correspond to the Cartesian directions of the crystal basis represented in ERS whereas the columns correspond to the Cartesian directions of the ERS represented in the crystal basis. For instance, the first row is the direction of the crystallographic <span class="math inline">\(x\)</span> axis in macroscopic frame and the last row is the normal direction to the surface’s plate observed from crystallographic perspective, as indicated in Figure <a href="#fig:ori_mat_info" data-reference-type="ref" data-reference="fig:ori_mat_info">[fig:ori_mat_info]</a>.</p>
<p>The second and last column (RD and ND in Figure <a href="#fig:ori_mat_info" data-reference-type="ref" data-reference="fig:ori_mat_info">[fig:ori_mat_info]</a>) can also form a simplified orientation representation called Miller indices. Miller indices are composed of two directions: <span class="math inline">\(\left(hkl\right)\)</span> the crystallographic direction of the plane parallel to the surface’s plate i.e. <span class="math inline">\(\left(hkl\right)\parallel ND\)</span>, and <span class="math inline">\(\left[uvw\right]\)</span> the crystallographic direction contained in <span class="math inline">\(\left(hkl\right)\)</span> plane and parallel to the rolling direction i.e. <span class="math inline">\(\left[uvw\right]\parallel RD\)</span> and <span class="math inline">\(\left[uvw\right]\mathrel\bot RD\)</span>. The remaining column (TD) is easily calculated from the cross product between <span class="math inline">\(\left(hkl\right)\)</span> and <span class="math inline">\(\left[uvw\right]\)</span>. Although there is an identity element for Miller indices (<span class="math inline">\(id\)</span>=<span class="math inline">\(\left(001\right)\left[100\right]\)</span>), no composition function nor inversion function exist. Therefore, Miller indices do not form a proper orientation representation.</p>
<p>Although rotation matrices are a simple orientation representation due its simplified operations for composition, identity and inversion, there some drawbacks. In the case of rotation in <span class="math inline">\(\mathbb{R}^{3}\)</span>, there are 9 elements to store for a 3 degrees freedom transformation, which means that 6 elements are implicitly redundant. Moreover, the space of rotation is a 9-dimension space which is practically impossible to visualize. And the rotation composition requires 27 multiplications and 18 additions.</p>
<h4 id="euler-angles">Euler angles</h4>
<p>Euler angles represent arbitrary rotations by composing a sequence of three rotations around three distinct axes. Different conventions or sequences of rotation exist with the Bunge convention being the most common in the field of crystallographic texture analysis. Bunge convention corresponds to the <span class="math inline">\(ZXZ\)</span> sequence where the first rotation is around the <span class="math inline">\(Z\)</span> axis with <span class="math inline">\(\varphi_{1}\)</span> angle followed with a rotation around <span class="math inline">\(X&#39;\)</span> (<span class="math inline">\(X\)</span> axis after the first rotation) with <span class="math inline">\(\Phi\)</span> angle and the last rotation is on <span class="math inline">\(Z&#39;&#39;\)</span> with <span class="math inline">\(\varphi_{2}\)</span> angle. This sequence can be visualized in figure <a href="#fig:EulerZXZ" data-reference-type="ref" data-reference="fig:EulerZXZ">[fig:EulerZXZ]</a>. The Euler angles can represented in the matrix from using the rotations in the equation <a href="#eq:simpleRotMat" data-reference-type="ref" data-reference="eq:simpleRotMat">[eq:simpleRotMat]</a>:</p>
<p><span class="math display">\[E\left(\varphi_{1},\Phi,\varphi_{2}\right)=R_{z}\left(\varphi_{2}\right)R_{x}\left(\Phi\right)R_{z}\left(\varphi_{1}\right)\label{eq:eulerMatrix}\]</span></p>
<p>By splitting the rotation around the main axes, the Euler angles allow a more compact representation than matrices using only three angles that is the minimum number of parameters necessary to represent a solid rotation with three degrees of freedom.</p>
<p>Although widely used in some scientific communities, the Euler angles do not have well know and clear composition and inverse functions. And the most critical drawback is the presence of singularities, it means that there are some rotation with more than one representation in the Euler space. For instance, the rotation <span class="math inline">\(\left(45,0,0\right)\)</span> is exactly the same as the rotation <span class="math inline">\(\left(0,0,45\right)\)</span> or <span class="math inline">\(\left(20,0,25\right)\)</span>.</p>
<h4 id="axis-angle">Axis-Angle</h4>
<p>Axis-Angle rotation is represented by a normalized direction <span class="math inline">\(\vec{v}\)</span> and a rotation angle <span class="math inline">\(\theta\)</span> around <span class="math inline">\(\vec{v}\)</span> following the right-hand grip rule. Like the Euler representation, it has a compact representation <span class="math inline">\(\mathbb{SO2\times\mathbb{R}}\)</span> but it has trivial inverse function. The use of an unique rotation axis in combination with an rotation angle makes this representation very human readable, specially for representing difference between rotations (i.e. misorientations at the grain boundaries). One should be aware the singularity that exists when <span class="math inline">\(\theta=0\)</span>, in this case the representation of the normalized direction is meaningless and any arbitrary<span class="math inline">\(\vec{v}\)</span> will represent the identity rotation.</p>
<p>The inverse rotation can be easily obtained by either reversing the direction vector or by negating the rotation angle. This also implies that some constraint has to be applied to the domain boundaries of the axis-angle space in order to avoid multiple equivalent representations. For instance, <span class="math inline">\(\left(\vec{v},\theta\right)=\left(\vec{-v},2\pi-\theta\right)\)</span> if <span class="math inline">\(0\leq\theta&lt;2\pi\)</span>. The solution is restrict <span class="math inline">\(\theta\)</span> in the range <span class="math inline">\(0\leq\theta&lt;\pi\)</span> or <span class="math inline">\(-\nicefrac{\pi}{2}\leq\theta&lt;\nicefrac{\pi}{2}\)</span> or even, although less desirable, restrict the <span class="math inline">\(\vec{v}\)</span> to be contained in half <span class="math inline">\(\mathbb{SO2}\)</span>.</p>
<h4 id="frank-rodriges">Frank-Rodriges</h4>
<p>The Frank-Rodriges has, as Euler angles, the most possible compact representation of rotations.</p>
<h4 id="quaternion">Quaternion</h4>
<h3 id="orientation-distribution">Orientation distribution</h3>
<h4 id="bingham-distribution">Bingham distribution</h4>
<h5 id="normalization-constant">Normalization constant</h5>
<p>The <em>generalized hypergeometric function</em><span lang="en-US"></span><a href="#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a> is defined as</p>
<p><span class="math display">\[_{p}F_{q}\left(a_{1},\ldots,a_{p};b_{1},\ldots,b_{q};z\right)=\sum_{j=0}^{\infty}{\textstyle \frac{\left(a_{1}\right)_{j}\ldots\left(a_{p}\right)_{j}}{\left(b_{1}\right)_{j}\ldots\left(b_{q}\right)_{j}}\frac{z^{j}}{j!}}\label{eq:generalized_hypergeometric}\]</span></p>
<p>Where <span class="math inline">\(a_{1},\ldots,a_{p},b_{1},\ldots,b_{q},z\mathbb{\in C}\)</span> and the <em>Pochhammer symbol</em> <span class="math inline">\(\left(x\right)_{n}\)</span>represents the rising factorial as the following</p>
<p><span class="math display">\[(x)_{n}=x(x+1)(x+2)\cdots(x+n-1)\]</span></p>
<p>The <em>confluent hypergeometric function</em>, also known as <em>Kummer’s function</em>, is a specific case of the <em>generalized hypergeometric function</em> where <span class="math inline">\(p=q=1\)</span>, therefore the <a href="#generalized_hypergeometric" data-reference-type="eqref" data-reference="generalized_hypergeometric">[generalized_hypergeometric]</a> becomes</p>
<p><span class="math display">\[_{1}F_{1}=\sum_{j=0}^{\infty}{\textstyle \frac{\left(a\right)_{j}}{\left(b\right)_{j}}\frac{z^{j}}{j!}}\]</span></p>
<p>Factorials are time consuming to calculate but no precomputed table can be used in this case because <em>Pochhammer symbol</em> involves real numbers. Alternatively, <em>Pochhammer symbol</em> for rising factorials can be calculated using the gamma function <span class="math inline">\(\Gamma\)</span></p>
<p><span class="math display">\[(x)_{n}=\frac{\Gamma(x+n)}{\Gamma(x)}\]</span></p>
<h5 id="multivariate-confluent-hypergeometric-function">Multivariate confluent hypergeometric function</h5>
<p>The multi-dimension confluent hypergeometric function is given by one of the Appell series functions</p>
<p><span class="math display">\[F_{1}(0,a_{1},\ldots,a_{n},b,x_{1},\ldots,x_{n})=\sum_{k_{1},\ldots,k_{n}}{\textstyle \frac{\left(a_{1}\right)_{k_{1}}\ldots\left(a_{n}\right)_{k_{n}}}{\left(b\right)_{k_{1}+\ldots+k_{n}}}\frac{x_{1}^{j}\ldots x_{n}^{j}}{k_{1}!\ldots k_{n}!}}\]</span></p>
<p>And its partial derivatives regarding <span class="math inline">\(x\)</span> are given by</p>
<p><span class="math display">\[\frac{\partial}{\partial x}F_{1}(a,b_{1},b_{2},c;x,y)=\frac{ab_{1}}{c}F_{1}(a+1,b_{1}+1,b_{2},c+1;x,y)\]</span></p>
<h4 id="hyper-spherical-harmonics">Hyper Spherical Harmonics</h4>
<figure>
<img src="\string%22mainmatter/img/oridist/HSH%20active%20and%20passive%20rotations\string%22.png" alt="Active and passive rotations on the quaternion space using HSH. The original orientations are: s_{1}=SO^{3}\:(\nicefrac{\pi}{2},\nicefrac{\pi}{2},\nicefrac{\pi}{2}) and s_{2}=SO^{3}\:(\nicefrac{\pi}{4},\nicefrac{\pi}{4},0). Both active and passive rotation are SO^{3}\:(\nicefrac{-\pi}{2},\nicefrac{\pi}{2},0)." style="width:100.0%" /><figcaption>Active and passive rotations on the quaternion space using HSH. The original orientations are: <span class="math inline">\(s_{1}=SO^{3}\:(\nicefrac{\pi}{2},\nicefrac{\pi}{2},\nicefrac{\pi}{2})\)</span> and <span class="math inline">\(s_{2}=SO^{3}\:(\nicefrac{\pi}{4},\nicefrac{\pi}{4},0)\)</span>. Both active and passive rotation are <span class="math inline">\(SO^{3}\:(\nicefrac{-\pi}{2},\nicefrac{\pi}{2},0)\)</span>.</figcaption>
</figure>
<figure>
<img src="\string%22mainmatter/img/oridist/HSH%20symmetryzation\string%22.png" alt="Enforcing symmetry on HSH." style="width:100.0%" /><figcaption>Enforcing symmetry on HSH.</figcaption>
</figure>
<h2 id="texture-sampling">Texture Sampling</h2>
<h3 id="introduction">Introduction</h3>
<p>Polycrystalline metallic solids are composed of a contiguous set of crystal grains. Such a set and its properties constitute the microstructure and can be partially described using statistical parameters like grain size, crystallographic orientation and misorientation distributions. To a large extent the microstructure of a polycrystal determines its engineering behavior by controlling <em>e.g.</em> mechanical, corrosion and magnetic properties. In the last decades a large number of models has been developed claiming to account for a variety of material responses and some of these may benefit from calculations employing 3D microstructures as an input.</p>
<p>During the development of a microstructurally based material model a set of different input parameters are required for validation and optimization. In order to avoid time-consuming and sophisticated 3D measurements of microstructures a framework for virtual microstructure generation is proposed here. A virtual microstructure is a model itself, capable of generating a numerical representation of numerous microstructural features that are able to substitute for experimental data when used as input to microstructural models. Virtual microstructures are very handy to produce test case samples, which can be used for fast modeling prototyping and microstructural design since they may cover a very large spectrum of microstructural state variables even outside the range of practical implementation. Such capacity helps one to find the boundary conditions and the crucial state variables in a model. It is important to state that the aim is not to completely replace experiments but reduce their number and improve their efficiency by predefining which samples are better suited for experimental validation. Once validated and with the boundary conditions checked, it is also useful to look for optimum microstructures when one wants to design a material.</p>
<p>In the past decades metallurgists and scientists have been looking at the microstructure and defined a broad range of parameters to characterize them. However to create a virtual microstructure the opposite exercise has to be done, <em>i.e.</em> starting from a set of microstructural state variables, conveniently expressed as statistical distribution functions, a 3D set of contiguous grains needs to be created which represents the virtual microstructure. Because microstructures are very complex objects some assumptions are required to simplify the framework. Therefore, it is assumed here that the microstructure is fully characterized by a set of crystal orientations of a single phase that are assembled in a contiguous volume, ignoring in-grain heterogeneities. The input parameters of the microstructure generator can be specified as a set of distribution functions and their relations like grain morphology, orientation and grain boundary character. Additional features such as number of neighbors, triple junction angles or clustering of some properties might be considered as well, but are ignored for the time being. The current paper will report the results when the grain size and texture distribution functions are given as input.</p>
<h3 id="method">Method</h3>
<p>In the proposed framework, surfaces are the main representative objects. Each grain is represented by a set of surfaces forming a closed volume rather than a set of subvolumes in a grid as <em>e.g.</em> voxels in a cubic grid space. This choice allows for a more precise description of grain boundaries and associated properties (such as <em>e.g.</em> local GB curvature), and on the practical side it also allows for a compact data description and thus a faster calculation. In the first version of the model the boundaries are composed of flat surfaces, but in future these flat surfaces will be converted to polynomial piecewise surfaces. If necessary, further post-processing conversion to voxels or meshes can be carried out for the sake of compatibility with others model formats such as <em>e.g.</em> finite elements and phase field modeling.</p>
<p>The grains are first created using the concept of Voronoi cells, which consist of a mathematical concept where a space <span class="math inline">\(\mathbb{R}^{n}\)</span> is partitioned starting from a set of points <span class="math inline">\(p\in\mathbb{R}^{n}\)</span>. Each cell is defined by a region in the space where all distances are closer to its central point <span class="math inline">\(p\)</span> than the central points from any other cell. Voronoi structures bear a one-to-one relation with Delaunay triangulation  <span class="citation" data-cites="aurenhammer1991voronoi">[@aurenhammer1991voronoi]</span>. Both concepts provide equivalent information but stored in different ways, the so called duality property, that allows a straightforward bijective conversion between them. Even though there are algorithms to directly calculate Voronoi cells, an indirect method that calculates the Delaunay triangulation first and then converts it to Voronoi cells is used here.</p>
<p>The key point to generate a proper grain size distribution using Voronoi cells is to find a proper set of central points that reproduces the user specified grain size distribution. The user provides the grain size distribution function <span class="math inline">\(f(gs)\)</span> as well as the lower and upper limits <span class="math inline">\(gs\in[a,b]\)</span>, thus defining the <em>target</em> distribution. If <span class="math inline">\(n\)</span> points are randomly placed in a box of which the size depends on the number of grains <span class="math inline">\(n\)</span> and the average grain size of the target distribution, the resultant distribution is the so-called Poisson-Voronoi which exhibits a lognormal distribution with a variance of <span class="math inline">\(0.424\)</span> <span class="citation" data-cites="xu2009topological">[@xu2009topological]</span>. Even though this distribution might be useful in some specific cases, in more general cases the target distribution will deviate from the lognormal one and may exhibit a different variance or even a bimodal structure. In order to transform the initial set of points in a valid one where the Voronoi cells follow the target distribution a RMC algorithm is used  <span class="citation" data-cites="mcgreevy2001reverse">[@mcgreevy2001reverse]</span>. Both target and current distributions are discretized into histograms with volume fractions <span class="math inline">\(p_{i}\)</span> in each bin and the error function described in equation <a href="#eq:gs_err" data-reference-type="ref" data-reference="eq:gs_err">[eq:gs_err]</a> is employed for convergence.</p>
<p>The orientation assignment starts once a suitable grain size distribution is found. The target distribution is obtained from a discretized ODF in Euler space. To the purpose of discretization the inverse of the CDF is sampled by a uniform distribution, very much similar to the method proposed by Toth and Van Houtte  <span class="citation" data-cites="toth1992discretization">[@toth1992discretization]</span>. The CDF is constructed by numerical integration of the ODF along its three angles, as describe in equation <a href="#eq:cdf" data-reference-type="ref" data-reference="eq:cdf">[eq:cdf]</a> where <span class="math inline">\(v_{i,j,k}\)</span> is the volume fraction in a discrete position of the Euler space.</p>
<p><span class="math display">\[\begin{aligned}
error_{GS}=\sum_{i=1}^{N}(p_{i}-p_{i}^{target})^{2}.\label{eq:gs_err}\\
error_{ODF}=\sum_{i=1}^{N}\sum_{j=1}^{M}\sum_{k=1}^{L}(v_{i,j,k}-v_{i,j,k}^{target})^{2}.\label{eq:odf_err}\\
CDF(N,M,L)=\sum_{i=1}^{N}\sum_{j=1}^{M}\sum_{k=1}^{L}v_{i,j,k}\sin\Phi\Delta\phi_{1}\Delta\Phi\Delta\phi_{2}.\label{eq:cdf}\end{aligned}\]</span></p>
<p>Even though the method described above allows a fair ODF sampling , each sampled orientation has implicitly the same weight or volume fraction. It means that when the orientations are associated to the grains and the grain set has a non-uniform volume fraction distribution, the resultant ODF is very much likely to be distorted. On the other hand there are an infinite set of orientations that when associated with a certain set of grains will result in equivalent ODFs. This shows how ill-posed the problem might be <em>i.e.</em> in its present form it is not guaranteed that a unique solution can be found. In order to specify a unique solution the missing state variables like misorientation or grain boundary character distributions should be included. For the moment the model does not include any of those parameters, therefore RMC will be applied to enforce a <em>possible</em> association between orientations and volume fractions using the error function described in equation <a href="#eq:odf_err" data-reference-type="ref" data-reference="eq:odf_err">[eq:odf_err]</a>.</p>
<h3 id="example">Example</h3>
<p>One example displaying the current capabilities of the virtual microstructure generator will be given. A set of 1000 grains was generated and fitted into a bimodal spectrum composed by overlapping two normal distributions. The first distribution, that was obtained by placing points randomly, is shown in figure <a href="#fig:odf_dist_target" data-reference-type="ref" data-reference="fig:odf_dist_target">[fig:odf_dist_target]</a>(a). As expected, it resembles a lognormal distribution with a variance of approximately <span class="math inline">\(0.43\)</span> that is typical for Poisson-Voronoi statistics. Finally, after the RMC iterations, the desired distribution is obtained as one can observe in figure <a href="#fig:odf_dist_target" data-reference-type="ref" data-reference="fig:odf_dist_target">[fig:odf_dist_target]</a>(b).</p>
<figure>
<img src="mainmatter/img/texsamp/fig1" alt="[fig:odf_dist_target]Generation of 1000 grains that correspond to the target distribution composed by two overlapping normal distributions (\mu_{1}=1,\;\sigma_{1}=0.5,\;\mu_{2}=5,\;\sigma_{2}=0.7). (a) The initial distribution after random positioning of points. (b) Final distribution after RMC iterations. (c) 3D section of the resultant grain set." style="width:100.0%" /><figcaption><span id="fig:odf_dist_target" label="fig:odf_dist_target">[fig:odf_dist_target]</span>Generation of 1000 grains that correspond to the target distribution composed by two overlapping normal distributions (<span class="math inline">\(\mu_{1}=1,\;\sigma_{1}=0.5,\;\mu_{2}=5,\;\sigma_{2}=0.7\)</span>). (a) The initial distribution after random positioning of points. (b) Final distribution after RMC iterations. (c) 3D section of the resultant grain set.</figcaption>
</figure>
<p>Once the grain set is defined, the following step is to create the texture by assigning orientations to each grain. Given a target ODF, orientations were sampled and assigned randomly to the grains, see figure <a href="#fig:recons_odf_brutal" data-reference-type="ref" data-reference="fig:recons_odf_brutal">[fig:recons_odf_brutal]</a>(b). As expected, the distribution does not match with the target distribution, figure <a href="#fig:recons_odf_brutal" data-reference-type="ref" data-reference="fig:recons_odf_brutal">[fig:recons_odf_brutal]</a>(a), because of the non-uniform grain size. After the RMC iterations a valid configuration was achieved as shown on figure <a href="#fig:recons_odf_brutal" data-reference-type="ref" data-reference="fig:recons_odf_brutal">[fig:recons_odf_brutal]</a>(c).</p>
<figure>
<img src="mainmatter/img/texsamp/Fig2" alt="[fig:recons_odf_brutal]Texture reconstruction. (a) Target ODF with typical \alpha-\gamma fibers obtained experimentally. (b) Initial ODF after random assignment of sampled orientations to grains. (c) Final ODF after RMC iterations. (d) Overlay of the previous three states." style="width:100.0%" /><figcaption><span id="fig:recons_odf_brutal" label="fig:recons_odf_brutal">[fig:recons_odf_brutal]</span>Texture reconstruction. (a) Target ODF with typical <span class="math inline">\(\alpha-\gamma\)</span> fibers obtained experimentally. (b) Initial ODF after random assignment of sampled orientations to grains. (c) Final ODF after RMC iterations. (d) Overlay of the previous three states.</figcaption>
</figure>
<h3 id="sampling-distribution">Sampling distribution</h3>
<p>Sampling is generation of a set of values that follows determined statistical descriptors. Therefore, sampling is inverse of the statistical analysis which derive statistical descriptors for a given set of values, also known as population. If the generated population is large enough, both initial statistical descriptors and statistical descriptors derived from the analysis of the generated population should be fairly close. For example, in figure <a href="#fig:SamplingNormal1D" data-reference-type="ref" data-reference="fig:SamplingNormal1D">[fig:SamplingNormal1D]</a> a normal distribution in sampled and the resultant points form a Gaussian distribution close to the original distribution.</p>
<p>The example above is very simple and the sampled points can be obtained even with an analytic equation from cumulative distribution function of the normal distribution. But Nature is not always so kind and the distributions derived from most of features in polycrystal, like grain size distribution, may have complex shape with more than one mode (peak with higher density of values). And in the specific case of crystallographic orientation distributions, it is even more complex due its higher dimension, symmetry and non-linearity of the orientation space.</p>
<p>There are many techniques for sampling multidimensional distributions but the majority are defined for Euclidean space. Some of them and a new one adapted for orientation space will be described in the following sections.</p>
<h4 id="inverse-transform-sampling">Inverse Transform Sampling</h4>
<p>This is a basic method for generating random samples from an arbitrary probability distribution function. Let <span class="math inline">\(p\left(x\right)\)</span> be a normalized probability distribution function defined over the interval <span class="math inline">\(\left[a,b\right]\)</span>, the method begins with the calculation of the cumulative distribution function:</p>
<p><span class="math display">\[F\left(x\right)=\int_{a}^{x}p\left(t\right)dt\]</span></p>
<p>Since <span class="math inline">\(p\left(x\right)\)</span> is normalized, <span class="math inline">\(F\left(a\right)=0\)</span> and <span class="math inline">\(F\left(b\right)=1\)</span>. The next step is to obtain the inverse of the cumulative distribution function, <span class="math inline">\(F^{-1}\left(u\right)\)</span> where:</p>
<p><span class="math display">\[\begin{aligned}\left\{ u\in\mathbb{R}\mid0\leq u\leq1\right\} \\
u=F\left(F^{-1}\left(u\right)\right)\\
a\leq F^{-1}\left(u\right)\leq b
\end{aligned}\]</span></p>
<p>Random values following <span class="math inline">\(p\left(x\right)\)</span> can be obtained by feeding the inverse of the cumulative distribution function with values from an <em>uniform</em> random distribution in the interval <span class="math inline">\(\left[0,1\right]\)</span>. Uniform random distribution is a probability distribution function with constant probability in its interval. This methodology is illustrated in figure <a href="#fig:InvSampling1D" data-reference-type="ref" data-reference="fig:InvSampling1D">[fig:InvSampling1D]</a>.</p>
<p>This technique is quite general and it works with any continuous or discrete probability functions, i.e. <span class="math inline">\(\left\{ p\left(x\right)\geq0\mid a\leq x\leq b\right\}\)</span>. If the cumulative function or its inverse do not have an analytic description or if them are quite difficult to be calculated, then a numerical integration and binary search can be used instead.</p>
<p>The inverse transform sampling is a very well accepted method for sampling uni-variate functions (one dimension). It can also be extended to higher dimensions, but it demands more complex calculation steps. In order to use it in higher dimensions it is necessary to calculate the conditional cumulative distribution function. For instance, in the bi-variate functions that would be written as</p>
<p><span class="math display">\[\begin{alignedat}{1}F_{XY}\left(x\mid y\right)=\dfrac{\iint p\left(x,y\right)dxdy}{\int p\left(x,y\right)dx}=\dfrac{F_{XY}\left(x,y\right)}{F_{Y}\left(y\right)}\end{alignedat}
,\]</span></p>
<p>where <span class="math inline">\(F_{XY}\left(x,y\right)\)</span> is the cumulative joint distribution and <span class="math inline">\(F_{Y}\left(y\right)\)</span> is the cumulative marginal distribution. A random sample <span class="math inline">\(\left(x,y\right)\)</span> can be obtained from two uniformly distributed values, <span class="math inline">\(u_{1}\)</span> and <span class="math inline">\(u_{2}\)</span>, in following manner,</p>
<p><span class="math display">\[\begin{alignedat}{1}y=F_{Y}^{-1}\left(u_{1}\right),\\
x=F_{X\mid Y}^{-1}\left(u_{2}\right).
\end{alignedat}\]</span></p>
<p>The calculation described above, for a two dimension function, can be reasonable in terms of complexity and calculation time, but it degrades rapidly when increasing the dimensionality. Therefore alternative techniques are used for dimensions higher than one and some of them will be reviewed in the following sections.</p>
<h4 id="rejection-sampling">Rejection Sampling</h4>
<p>In order to circumvent the drawbacks of sampling probability functions with higher dimensions, a family of sampling techniques called Monte Carlo Sampling is used. The most basic member of this family is the so called rejection sampling. The main concept is to draw random values from a known probability function where a sampling technique is also known and, preferable, fast. This function, called proposal function and represented by <span class="math inline">\(Q\left(x\right)\)</span>, has to be larger than the target probability function <span class="math inline">\(p\left(x\right)\)</span>, i.e. <span class="math inline">\(Q\left(x\right)\geq p\left(x\right)\)</span>for any <span class="math inline">\(x\)</span>. Let <span class="math inline">\(X\)</span> be a proposed point sampled from <span class="math inline">\(Q\text{\ensuremath{\left(x\right)}}\)</span>, then <span class="math inline">\(X\)</span> is accepted as a random point of <span class="math inline">\(p\left(x\right)\)</span> with probability <span class="math inline">\(p\left(x\right)/Q\left(x\right)\)</span>. If the point is rejected then a new point is proposed. The efficiency of this algorithm is given by the overall accepting ratio that can be derived from the ratio between the area under the target function and the area under the proposed function, see figure <a href="#fig:rejectSamp" data-reference-type="ref" data-reference="fig:rejectSamp">[fig:rejectSamp]</a>. This implies that good accepting ratios are obtained when both propose and target distributions are similar.</p>
<p>[Rejection sampling.]<span id="fig:rejectSamp" label="fig:rejectSamp">[fig:rejectSamp]</span>Illustration of the rejection sampling method. The overall acceptance ratio is given by ratio between the area under <span class="math inline">\(p\left(x\right)\)</span> and the area under <span class="math inline">\(Q\left(x\right)\)</span>.</p>
<p>Some times, when the target distribution is too complex or there is no <em>a priori</em> knowledge about it and, the uniform distribution can be used as proposal distribution. Although the uniform distribution can be efficiently sampled, it normally leads to a low efficiency in the rejection sampling. This is exactly the case when sampling in the orientation space.</p>
<h4 id="monte-carlo-markov-chain-sampling">Monte Carlo Markov Chain Sampling</h4>
<p>The main limitation in the rejection sampling method is the need of similar proposal function that is also easy to sample. A subclass of algorithms called MCMC address this limitation by eliminating the need of a user defined proposal distribution. The proposal distribution is implicit created using the Markov chain principle. The Markov chain is nothing else then a sequence of states (in this case points drawn from a proposal distribution) where the current state depends on the previous states. This means that points using only Monte Carlo technique are independent while points using MCMC have some degree of correlation.</p>
<p>A pure Monte Carlo process is memoryless because it generates an independent sequence of points. Whereas the MCMC uses the history (correlation) to propose points with increased likelihood of being accepted. For instance, to estimate what is the probability that a standard normal random variable is less than <span class="math inline">\(0.5\)</span>, one could generate thousands of independent points following a standard normal distribution and then count up the number lower than <span class="math inline">\(0.5\)</span>. That would be a Monte Carlo process. But if it is unknown how to draw independent normal random variables, one could use a process that proposes a point by adding some uniform random number between <span class="math inline">\(-0.25\)</span> and <span class="math inline">\(0.25\)</span> to the current point. If the proposed point is a good candidate then it is kept and promoted as current point otherwise the original current point is kept and the process starts again. That is an MCMC process. The MCMC introduces a local effect, if the current point <span class="math inline">\(X\)</span> is a good candidate than its immediate neighborhood may also be. A sequence of points generated in this way is called random walk.</p>
<p>Many MCMC algorithms have been developed but the two most populars are the Metropolis-Hastings and Gibbs. Most of them are designed to work the Euclidian space <span class="math inline">\(\mathbb{R}^{n}\)</span> which may cause problems when used for sampling ODF’s.</p>
<h3 id="new-method-of-sampling-in-the-orientation-space">New Method of Sampling in the Orientation Space</h3>
<p>A new method of sampling distribution functions in the orientation space is proposed here. The new method can efficiently sample arbitrary distribution functions in the orientation space, works with any representation of rotation (e.g. matrix or quaternion) and do not need any specific data structure like regular grids. It is a modification of a MCMC technique called slice sampling inspired by another MCMC technique called hit and run sampling. Both techniques and the new method are explained bellow.</p>
<h4 id="hit-and-run">Hit and Run</h4>
<p>Hit and Run sampling was initially developed for creating uniform random distributions in arbitrary closed domain. For instance, place random points inside a pentagon or a star. Lately, it was modified for sampling arbitrary probability functions. The original Hit and Run is described in algorithm <a href="#alg:basic-hit=000026run" data-reference-type="ref" data-reference="alg:basic-hit=000026run">[alg:basic-hit=000026run]</a>. Note that the random direction <span class="math inline">\(D\)</span> and the the domain of the probability function <span class="math inline">\(p\left(x\right):\mathbb{R}^{n}\rightarrow\mathbb{R}^{+}\)</span> have the same dimension <span class="math inline">\(\mathbb{R}^{n}\)</span>, e.g. two dimensions shapes have random directions as unit vectors from a circle. A visual description of the algorithm of 2D shapes is illustrated in figure <a href="#fig:hit=000026run" data-reference-type="ref" data-reference="fig:hit=000026run">[fig:hit=000026run]</a>.</p>
<p>[Original Hit and Run algorithm.][[fig:hit=000026run]]{#fig:hit=000026run label=“fig:hit=000026run”}Visualization of the original Hit and Run algorithm: (a) an arbitrary start point is given, (b) choose a random direction, (c) pick a point at random distance, (d) if the point is outside the domain then try it again and (e) final random walk.</p>
<p>The analogy is given by a snipper who shots at a random direction and distance, if he hits the target then he moves to that position otherwise he tries again. The sequence of points clearly generates a Markov chain. The criteria of acceptance in the original design (uniform distribution in closed domains) is trivial. If <span class="math inline">\(D\)</span> is the closed domain then <span class="math inline">\(X\)</span> is only accepted if <span class="math inline">\(X\)</span> is inside the <span class="math inline">\(D\)</span>. The modified version, for sampling arbitrary probability functions, has a more complex sequence that will not explained here. The advantage of this algorithm is the ability of explorer the entire space and sample isolated regions. This is important in the case of ODF’s because them may have multiple isolated peaks. The disadvantage is the need of tuning the range (the maximum distance) where <span class="math inline">\(k\)</span> is sampled from. If <span class="math inline">\(k\)</span> is to small then the output sequence is strong correlated, the random walk is quite local and space might not be well explored. Whereas if <span class="math inline">\(k\)</span> is too large then efficiency is quite low.</p>
<h4 id="slice-sampling">Slice sampling</h4>
<p>Slice sampling is also a very popular MCMC sampling technique. It is based on the principle that any region under any distribution function have uniform density and, therefore, can be uniformly sampled, such a region is a slice of the probability function at certain intensity. Figure <a href="#fig:sliceprinciple" data-reference-type="ref" data-reference="fig:sliceprinciple">[fig:sliceprinciple]</a> illustrate this principle for a probability function <span class="math inline">\(p\left(x\right)\)</span> in one dimension.</p>
<p>[Principle of slice sampling.]<span id="fig:sliceprinciple" label="fig:sliceprinciple">[fig:sliceprinciple]</span>Slice sampling is based on the principle that a slice of the probability function <span class="math inline">\(p\left(x\right)\)</span> at a level <span class="math inline">\(y\)</span> can be uniformly sampled.</p>
<p>In order to sample the target function the slice sampler randomly alternate the slicing level covering the entire distribution function. Algorithm <a href="#alg:basic-slice" data-reference-type="ref" data-reference="alg:basic-slice">[alg:basic-slice]</a> describes a single iteration step to obtain one sampled point. There are two crucial parts in this algorithm. The first one, defined in the line <a href="#basic-slice:getslice" data-reference-type="ref" data-reference="basic-slice:getslice">[basic-slice:getslice]</a>, has to find the slice at given level <span class="math inline">\(y\)</span>. A slice is nothing else then the region enclosed by the level set<a href="#fn2" class="footnote-ref" id="fnref2"><sup>2</sup></a>, for instance, a slice in one dimension function is a set of discrete points, in two dimensions it is a isoline (or contour line) and in three dimensions it is a isosurface. Figure <a href="#fig:slicebasic1D" data-reference-type="ref" data-reference="fig:slicebasic1D">[fig:slicebasic1D]</a> illustrates the slice sampling for one dimensional probability function.</p>
<p>[Illustration of slice sampling in 1D.]<span id="fig:slicebasic1D" label="fig:slicebasic1D">[fig:slicebasic1D]</span> Illustration of slice sampling technique described in the algorithm <a href="#alg:basic-slice" data-reference-type="ref" data-reference="alg:basic-slice">[alg:basic-slice]</a> using one dimension probability function.</p>
<h3 id="references" class="unnumbered">References</h3>
<p>mainmatter/bib/texsamp</p>
<h1 id="austenite-reconstruction">Austenite Reconstruction</h1>
<h2 id="fully-automated-orientation-relationship-calculation">Fully automated orientation relationship calculation</h2>
<h2 id="prior-austenite-reconstruction">Prior austenite reconstruction</h2>
<p>Two new methods, one for determining the experimentally observed OR and another for reconstructing prior austenite phase, are proposed. Both methods are based on the angular deviation of the OR at the grain boundaries. The first algorithm identifies the optimum OR using the misorientation distribution of the entire scan i.e. without manual selection of parent grains. The second algorithm reconstructs the parent phase using a random walk clustering technique that identifies groups of closely related grains based on their angular deviation of the OR.</p>
<h3 id="introduction-5">Introduction</h3>
<p>Most of the steelmaking process occurs at elevated temperature which, for most steel grades, implies that part of the processing occurs in the austenitic phase. The characterization of the high-temperature austenitic phase is of great value to understand and control the microstructure evolution during the entire production chain. But the direct observation of the austenitic phase is not trivial. It can only be done at elevated temperatures, and therefore, it can only be observed within very specialized <em>in-situ</em> equipment like EBSD with a hot stage<span class="citation" data-cites="seward_high-temperature_2002">[@seward_high-temperature_2002]</span>. Moreover, such sophisticated measurements are always done under simulating laboratory conditions, which are not necessarily representative of the real process.</p>
<p>Alternatively, indirect measurements are done at the room temperature. If, at this temperature, the phase transformation has already completed then the prior austenite microstructure can observed by: (a) optical microscopy with special etching techniques that revel the original grain boundaries<span class="citation" data-cites="bechet_new_1955">[@bechet_new_1955]</span>, (b) reconstruction of OIM obtained with standard EBSD equipment<span class="citation" data-cites="cayron_reconstruction_2006 miyamoto_mapping_2010 abbasi_approach_2012 tari_back_2013 bernier_alternative_2014">[@cayron_reconstruction_2006; @miyamoto_mapping_2010; @abbasi_approach_2012; @tari_back_2013; @bernier_alternative_2014]</span>. The latter method identifies and groups product grains derived from a single parent (austenitic) grain. This technique depends on the presence of a specific OR between parent and product phases, and therefore, it only applies to diffusionless phase transformations. This work introduces two new methods aiming to improve the current-state-of-the-art in prior austenite reconstruction.</p>
<h3 id="orientation-relationship-calculation">Orientation relationship calculation</h3>
<p>One of the main characteristics of martensitic transformations is the presence of a specific OR between parent and product phases. Although there are some theoretical orientation relationships proposed such as the KS or NW correspondences for steels, a more accurate OR can only be derived from experimental data. The available methods<span class="citation" data-cites="miyamoto_accurate_2009 humbert_refinement_2011">[@miyamoto_accurate_2009; @humbert_refinement_2011]</span> for OR identification depend on the manual selection of parent grains, which is time consuming and in some cases, depending on the microstructure, impractical.</p>
<p>The method proposed here can derive the OR from an orientation scan in a fully automated manner and it is based on the misorientation between neighboring grains. There are two possible situations where the OR can be observed. The first one is between a parent grain and its product grain (when still a residual fraction of the parent phase is present in the product microstructure), cf. (<a href="#eq:1" data-reference-type="ref" data-reference="eq:1">[eq:1]</a>). The second case is between product grains sharing the same parent and involves a double OR transformation, cf. (<a href="#eq:2" data-reference-type="ref" data-reference="eq:2">[eq:2]</a>). In the ideal conditions that the proposed OR is valid, the angular deviation (<span class="math inline">\(\Delta OR\)</span>) is equal to <span class="math inline">\(0\)</span>.</p>
<p>=[font=]</p>
<p>The algorithm finds the optimized OR transformation (<span class="math inline">\(T^{\alpha&#39;\leftrightarrow\gamma}\)</span>) that minimizes the average angular deviation for all grain boundaries or for a selected subset of them. The number of grain boundaries exhibiting this OR should be vastly larger than the number of prior parent grain boundaries. This is a reasonable assumption since the martensitic phase transformation produces grain refinement and all the new grain boundaries have misorientations that obey the OR transformation.</p>
<p><span class="math display">\[T_{m}^{\alpha&#39;\leftrightarrow\gamma}\left(Og^{\alpha&#39;}\right)\left(Og^{\gamma}\right)^{-1}=\Delta OR\label{eq:1}\]</span></p>
<p><span class="math display">\[T_{m}^{\alpha&#39;\leftrightarrow\gamma}T_{n}^{\gamma\leftrightarrow\alpha&#39;}\left(Og_{a}^{\alpha&#39;}\right)\left(Og_{b}^{\alpha&#39;}\right)^{-1}=\Delta OR\label{eq:2}\]</span></p>
<p><img src="mainmatter/img/ausrec/sample1/alpha+gamma" title="fig:" alt="[fig:recons]Validation of reconstruction algorithm on Fe-Ni alloy: (a) initial OIM before reconstruction, (b) retained austenite and expected prior austenite GB, (c) reconstruction after the first iteration and (d) second and final step of reconstruction." /><br />
(a)</p>
<p><img src="mainmatter/img/ausrec/sample1/RA+GB" title="fig:" alt="[fig:recons]Validation of reconstruction algorithm on Fe-Ni alloy: (a) initial OIM before reconstruction, (b) retained austenite and expected prior austenite GB, (c) reconstruction after the first iteration and (d) second and final step of reconstruction." /><br />
(b)</p>
<p><img src="mainmatter/img/ausrec/sample1/1st+GB" title="fig:" alt="[fig:recons]Validation of reconstruction algorithm on Fe-Ni alloy: (a) initial OIM before reconstruction, (b) retained austenite and expected prior austenite GB, (c) reconstruction after the first iteration and (d) second and final step of reconstruction." /><br />
(c)</p>
<p><img src="mainmatter/img/ausrec/sample1/2nd+GB" title="fig:" alt="[fig:recons]Validation of reconstruction algorithm on Fe-Ni alloy: (a) initial OIM before reconstruction, (b) retained austenite and expected prior austenite GB, (c) reconstruction after the first iteration and (d) second and final step of reconstruction." /><br />
(d)</p>
<p>Two strategies were employed in order to calculate the grain boundary misorientations. One is based on the average orientation of both neighboring grains. The other one is based on the orientation in the immediate vicinity of the grain boundary, where only the first layer of orientations at each side of the grain boundary is selected. Slightly different values of OR are obtained by the two strategies due to plastic strain accommodation during phase transformation and associated orientation gradients in bulk of the grains<span class="citation" data-cites="miyamoto_accurate_2009">[@miyamoto_accurate_2009]</span>.</p>
<p>This new method was validated with a low Nb steel alloy with carbon content around <span class="math inline">\(0.05\%\)</span>. Figure <a href="#fig:ORhist" data-reference-type="ref" data-reference="fig:ORhist">[fig:ORhist]</a> compares the distribution of angular deviation using the theoretical KS OR and the optimized OR, it can be noticed that the distribution shifts to the left, i.e. reducing the overall error, when the optimized OR is used. Better results are obtained when considering orientations in the immediate vicinity of the grain boundary compared to considering grain averaged orientations. Figure <a href="#fig:ORcomp" data-reference-type="ref" data-reference="fig:ORcomp">[fig:ORcomp]</a> compares the optimized OR for the low Nb sample with two theoretical ORs and one reference value<span class="citation" data-cites="miyamoto_accurate_2009">[@miyamoto_accurate_2009]</span> that contains comparable amount of carbon. The optimized OR is in good agreement with the reference value.</p>
<h3 id="parent-phase-reconstruction">Parent phase reconstruction</h3>
<p>A new method, equally based on grain boundary misorientations, is proposed for the parent phase reconstruction. The key concept of this method is the use of a graph clustering algorithm to find groups of closely related grains that originate from a single parent grain. The Markov Clustering algorithm<span class="citation" data-cites="dongen_graph_2001 schaeffer_graph_2007">[@dongen_graph_2001; @schaeffer_graph_2007]</span> is used because of the following features:</p>
<ul>
<li><p>It is based on the probabilities of random walks through the graph.</p></li>
<li><p>It identifies natural cuts and clusters in the graph without the need to specify threshold values of allowable angular deviations or the necessity to specify a predefined number of clusters</p></li>
<li><p>There is only one parameter that controls the cluster coarsening.</p></li>
<li><p>Excellent noise tolerance.</p></li>
<li><p>Fast calculation time.</p></li>
</ul>
<p>In order to use the clustering algorithm, a graph has to be derived from the OIM in the following way: (a) each grain, product or parent, becomes a node in the graph, (b) each grain boundary becomes an edge connecting two neighboring nodes (grains) and (c) each edge receives a value based on the equation (<a href="#eq:1" data-reference-type="ref" data-reference="eq:1">[eq:1]</a>) or (<a href="#eq:2" data-reference-type="ref" data-reference="eq:2">[eq:2]</a>), which determines the probability of the two neighboring grains being products of the same parent. Once the graph is constructed, the clusters are determined using the highest level of coarsening. Then each cluster forms a parent grain and its orientation is calculated by an optimization algorithm that minimizes the average angular deviation using the equation (<a href="#eq:1" data-reference-type="ref" data-reference="eq:1">[eq:1]</a>).</p>
<p>The first iteration described above may result in some of the clusters containing more than one parent grain because of the initial coarsening level. These grains can be identified by its higher average angular deviation, and therefore, they should be further refined by running an extra iteration step with reduced coarsening level. The refinement procedure should be repeated many times until all parent grains have low average error.</p>
<p>A Fe-Ni 29% sample was used to validate the proposed reconstruction method. The OIM after the martensitic phase transformation with still 10% retained austenite is shown in the figure <a href="#fig:recons" data-reference-type="ref" data-reference="fig:recons">[fig:recons]</a>a. The expected parent microstructure is visualized in figure <a href="#fig:recons" data-reference-type="ref" data-reference="fig:recons">[fig:recons]</a>b by the retained austenite and the traces of high angular deviation (<span class="math inline">\(&gt;10^{\circ}\)</span>). Figure <a href="#fig:recons" data-reference-type="ref" data-reference="fig:recons">[fig:recons]</a>c shows the reconstruction after the first iteration, showing that some reconstructed grains incorporate more than one parent grain. The final microstructure is shown in figure <a href="#fig:recons" data-reference-type="ref" data-reference="fig:recons">[fig:recons]</a>d after an extra step of refinement.</p>
<p>A careful look at the figure <a href="#fig:recons" data-reference-type="ref" data-reference="fig:recons">[fig:recons]</a>d shows that some unexpected features are visible at twin boundaries in parent grains and some grains are over refined. The current implementation of the reconstruction software is quite simple and does not include any special rule for treating this type of boundaries or for re-merging over-divided clusters.</p>
<h3 id="conclusion">Conclusion</h3>
<p>Tolerance error reduction and noise immunity are two fundamental strategies for the success of prior austenite reconstruction. The use of optimized ORs reduces the overall error but the identification by previous techniques requires manual selection of parent grains. The method proposed here identifies an optimized OR, whereby the entire orientation scan is considered and the result is obtained without user intervention.</p>
<p>Markov clustering seems a promising technique for parent grain reconstruction due its noise tolerance and fast calculation time. The present results are satisfactory considering the initial stage of development and the simple implementation. Further work on the special treatment of twin boundaries and cluster re-merging will be done.</p>
<h3 id="references-1" class="unnumbered">References</h3>
<p>mainmatter/bib/ausrec</p>
<h2 id="model-validation-and-application">Model Validation and Application</h2>
<h1 id="appendix">Appendix</h1>
<h2 id="delunay-triangulation">Delunay Triangulation</h2>
<p><span class="math inline">\(SD\left(D\right)=[m\left(D\right)-m_{&lt;A,B,C&gt;}]\cdot\dfrac{\left(a-b\right)\times\left(a-c\right)}{\parallel\left(a-b\right)\times\left(a-c\right)\parallel}\)</span></p>
<p><span class="math inline">\(\left[\begin{array}{cccc} 1 &amp; a_{x} &amp; a_{y} &amp; a_{z}\\ 1 &amp; b_{x} &amp; b_{y} &amp; b_{z}\\ 1 &amp; c_{x} &amp; c_{y} &amp; c_{z}\\ 1 &amp; d_{x} &amp; d_{y} &amp; d_{z} \end{array}\right]\left[\begin{array}{c} \parallel m\left(D\right)\parallel^{2}-w_{m}\\ -2m_{x}\left(D\right)\\ -2m_{y}\left(D\right)\\ -2m_{z}\left(D\right) \end{array}\right]=-\left[\begin{array}{c} \parallel a\parallel^{2}-w_{a}\\ \parallel b\parallel^{2}-w_{b}\\ \parallel c\parallel^{2}-w_{c}\\ \parallel d\parallel^{2}-w_{d} \end{array}\right]\)</span></p>
<p><span class="math inline">\(\left[\begin{array}{ccc} b_{x}-a_{x} &amp; b_{y}-a_{x} &amp; b_{z}-a_{x}\\ c_{x}-a_{x} &amp; c_{y}-a_{x} &amp; c_{z}-a_{x}\\ d_{x}-a_{x} &amp; d_{y}-a_{x} &amp; d_{z}-a_{x} \end{array}\right]\left[\begin{array}{c} -2m_{x}\left(D\right)\\ -2m_{y}\left(D\right)\\ -2m_{z}\left(D\right) \end{array}\right]=-\left[\begin{array}{c} \parallel b\parallel^{2}-\parallel a\parallel^{2}-w_{b}+w_{a}\\ \parallel c\parallel^{2}-\parallel a\parallel^{2}-w_{c}+w_{a}\\ \parallel d\parallel^{2}-\parallel a\parallel^{2}-w_{d}+w_{a} \end{array}\right]\)</span></p>
<p><span class="math inline">\(M^{T}[-2m\left(D\right)]=-\alpha\)</span></p>
<p>where</p>
<p><span class="math inline">\(M=\left[\begin{array}{ccc} b_{x}-a_{x} &amp; c_{x}-a_{x} &amp; d_{x}-a_{x}\\ b_{y}-a_{y} &amp; c_{y}-a_{y} &amp; d_{y}-a_{y}\\ b_{z}-a_{z} &amp; c_{z}-a_{z} &amp; d_{z}-a_{z} \end{array}\right]\)</span> <span class="math inline">\(\alpha=\left[\begin{array}{c} \parallel b\parallel^{2}-\parallel a\parallel^{2}-w_{b}+w_{a}\\ \parallel c\parallel^{2}-\parallel a\parallel^{2}-w_{c}+w_{a}\\ \parallel d\parallel^{2}-\parallel a\parallel^{2}-w_{d}+w_{a} \end{array}\right]\)</span></p>
<p>let <span class="math inline">\(\left(Q,R\right)=qrDecomp\left(M\right)\)</span></p>
<p><span class="math inline">\(M^{T}[-2m\left(D\right)]=R^{T}[-2Q^{T}m\left(D\right)]=R^{T}\mu\)</span></p>
<p><span class="math inline">\(m\left(D\right)=-\frac{1}{2}Q\mu=-\frac{1}{2}\left(q_{1}\mu_{x}+q_{2}\mu_{y}+q_{3}\mu_{z}\right)\)</span></p>
<p>where <span class="math inline">\(\mu\)</span> can be easily solved since it is a lower triangular matrix</p>
<p><span class="math inline">\(R^{T}\mu=-\alpha\)</span></p>
<p><span class="math inline">\(\mu_{x}=\dfrac{-\alpha_{x}}{r_{11}}\)</span></p>
<p><span class="math inline">\(\mu_{y}=\dfrac{-\alpha_{x}-\mu_{x}r_{12}}{r_{22}}\)</span></p>
<p><span class="math inline">\(\mu_{z}=\dfrac{-\alpha_{z}-\mu_{x}r_{13}-\mu_{y}r_{23}}{r_{33}}\)</span></p>
<h2 id="misorientation-definition">Misorientation definition</h2>
<p>Rotations can be seen as functions that map one vector space into an other.</p>
<p><span class="math display">\[g\,:\,s\rightarrow t\]</span></p>
<p>Rotations can be composed using function composition.</p>
<p><span class="math display">\[g_{sv}=g_{tv}\cdot g_{st}\]</span></p>
<p>where <span class="math inline">\(g_{sv}\,:\,s\rightarrow v\)</span>; <span class="math inline">\(g_{tv}\,:\,t\rightarrow v\)</span>; <span class="math inline">\(g_{st}\,:\,s\rightarrow t\)</span>.</p>
<p>Let <span class="math inline">\(g_{A}\)</span> and <span class="math inline">\(g_{B}\)</span> be two rotations that bring the reference frame to the frames A and B, respectively. And <span class="math inline">\(\Delta g_{AB}\)</span> the rotation that brings the frame A to B.</p>
<p><span class="math display">\[g_{B}=\Delta g_{AB}\cdot g_{A}\]</span></p>
<p><span class="math display">\[g_{B}\cdot g_{A}^{-1}=\Delta g_{AB}\cdot g_{A}\cdot g_{A}^{-1}\]</span></p>
<p><span class="math display">\[g_{B}\cdot g_{A}^{-1}=\Delta g_{AB}\]</span></p>
<p>It also exist an inverse rotation that brings B to A, <span class="math inline">\(\Delta g_{BA}\)</span>. In such a case,</p>
<p><span class="math display">\[g_{A}=\Delta g_{BA}\cdot g_{B}\]</span></p>
<p><span class="math display">\[g_{A}\cdot g_{B}^{-1}=\Delta g_{BA}\cdot g_{B}\cdot g_{B}^{-1}\]</span></p>
<p><span class="math display">\[g_{A}\cdot g_{B}^{-1}=\Delta g_{BA}\]</span></p>
<p>Rotation compositions are not commutative, so</p>
<p><span class="math display">\[g_{B}\cdot g_{A}^{-1}\neq g_{A}^{-1}\cdot g_{B}\]</span></p>
<p>If we enforce the first element to be the inverse</p>
<p><span class="math display">\[g_{A}^{-1}\cdot g_{B}=g_{A}^{-1}\cdot\Delta g_{AB}\cdot g_{A}\]</span></p>
<p><span class="math display">\[\begin{aligned}
g_{A}^{-1}\cdot g_{B} &amp; = &amp; \overline{\Delta g_{AB}}\end{aligned}\]</span></p>
<p>then the result will be the conjugate of the misorientation, which, if coverted to axis-rotation pair, will result the same rotation <span class="math inline">\(\omega\)</span> but with different axis from <span class="math inline">\(\Delta g_{AB}\)</span>.</p>
<blockquote>
<p>Definition 2.12 (conjugate elements): If <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span> are elements of <span class="math inline">\(G\)</span>, then <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span> are conjugate elements in <span class="math inline">\(G\)</span> if there exists an element <span class="math inline">\(g\)</span> such that <span class="math inline">\(b=gag^{-1}\)</span> . If <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span> are conjugate, we write <span class="math inline">\(a\backsim b\)</span>.</p>
<p>This notion of conjugation is of great importance to physics applications, since conjugation is essentially a similarity transformation. For example, in the rotation group, if <span class="math inline">\(a\)</span> denotes a rotation by <span class="math inline">\(30^{\circ}\)</span> about the <span class="math inline">\(x\)</span>-axis, then any rotation by <span class="math inline">\(30^{\circ}\)</span> is conjugate to a since rotations about different axes are related by a similarity transformation.<a href="#fn3" class="footnote-ref" id="fnref3"><sup>3</sup></a></p>
</blockquote>
<p>On the other hand, the relation between both misorientations is given by</p>
<p><span class="math display">\[g_{B}\cdot g_{B}^{-1}=\Delta g_{AB}\cdot g_{A}\cdot g_{B}^{-1}\]</span></p>
<p><span class="math display">\[I=\Delta g_{AB}\cdot g_{A}\cdot g_{B}^{-1}=\Delta g_{AB}\cdot\Delta g_{BA}\]</span></p>
<p><span class="math display">\[\Delta g_{AB}=(\Delta g_{BA})^{-1}\]</span></p>
<h2 id="colophon" class="unnumbered">Colophon</h2>
<p>This document was typeset using the typographical look-and-feel <code>classicthesis</code></p>
<section class="footnotes">
<hr />
<ol>
<li id="fn1"><p>Uno il nomine integre, lo tote tempore anglo-romanic per, ma sed practic philologos historiettas.<a href="#fnref1" class="footnote-back">↩</a></p></li>
<li id="fn2"><p>Mathematically, level set is defined as the set of points where a function has same predefined value. It has the form <span class="math inline">\(L_{y}\left(p\right)=\left\{ x\mid p\left(x\right)=y\right\}\)</span>.<a href="#fnref2" class="footnote-back">↩</a></p></li>
<li id="fn3"><p>2 Subgroups and conjugate elements. http://pauli.physics.lsa.umich.edu/p452/gt02.pdf<br />
see, Group Theoretical Methods and Applications to Molecules and Crystals, page 62<a href="#fnref3" class="footnote-back">↩</a></p></li>
</ol>
</section></div>
</div>
<footer>
	<hr />
	<p>Edgar Gomes de Araujo - 2019</p>
</footer>
</body>
</html>
